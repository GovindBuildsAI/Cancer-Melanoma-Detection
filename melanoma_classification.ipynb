{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIIM-ISIC Melanoma Classification\n",
    "## Deep Learning Model for Melanoma Detection\n",
    "\n",
    "This notebook implements a CNN-based classifier for melanoma detection using the SIIM-ISIC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Paths (adjust based on your Kaggle data structure)\n",
    "TRAIN_CSV = '/kaggle/input/siim-isic-melanoma-classification/train.csv'\n",
    "TEST_CSV = '/kaggle/input/siim-isic-melanoma-classification/test.csv'\n",
    "TRAIN_IMG_DIR = '/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\n",
    "TEST_IMG_DIR = '/kaggle/input/siim-isic-melanoma-classification/jpeg/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(train_df['target'].value_counts())\n",
    "\n",
    "# Display first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=train_df, x='target')\n",
    "plt.title('Class Distribution (0: Benign, 1: Malignant)')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Check for class imbalance\n",
    "melanoma_count = train_df['target'].sum()\n",
    "benign_count = len(train_df) - melanoma_count\n",
    "print(f\"\\nClass Imbalance Ratio: {benign_count/melanoma_count:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add full image paths\n",
    "train_df['image_path'] = train_df['image_name'].apply(lambda x: os.path.join(TRAIN_IMG_DIR, f'{x}.jpg'))\n",
    "test_df['image_path'] = test_df['image_name'].apply(lambda x: os.path.join(TEST_IMG_DIR, f'{x}.jpg'))\n",
    "\n",
    "# Split training data into train and validation\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=train_df['target']\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(train_data)} samples\")\n",
    "print(f\"Validation set: {len(val_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Show 4 benign and 4 malignant samples\n",
    "benign_samples = train_df[train_df['target'] == 0].sample(4)\n",
    "malignant_samples = train_df[train_df['target'] == 1].sample(4)\n",
    "samples = pd.concat([benign_samples, malignant_samples])\n",
    "\n",
    "for idx, (_, row) in enumerate(samples.iterrows()):\n",
    "    img = Image.open(row['image_path'])\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(f\"{'Malignant' if row['target'] == 1 else 'Benign'}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation and Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights to handle imbalance\n",
    "melanoma_count = train_data['target'].sum()\n",
    "benign_count = len(train_data) - melanoma_count\n",
    "total = len(train_data)\n",
    "\n",
    "class_weights = {\n",
    "    0: total / (2 * benign_count),\n",
    "    1: total / (2 * melanoma_count)\n",
    "}\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Only rescaling for validation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col='image_path',\n",
    "    y_col='target',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_data,\n",
    "    x_col='image_path',\n",
    "    y_col='target',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='raw',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    Build EfficientNetB3-based transfer learning model\n",
    "    \"\"\"\n",
    "    # Load pre-trained EfficientNetB3\n",
    "    base_model = EfficientNetB3(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "model, base_model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_auc',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=7,\n",
    "    mode='max',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_auc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model - Phase 1: Train only top layers\n",
    "print(\"Phase 1: Training top layers...\")\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning - Phase 2: Unfreeze and train entire model\n",
    "print(\"\\nPhase 2: Fine-tuning entire model...\")\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE/10),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr, early_stop, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine histories\n",
    "history = {\n",
    "    'loss': history_phase1.history['loss'] + history_phase2.history['loss'],\n",
    "    'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss'],\n",
    "    'auc': history_phase1.history['auc'] + history_phase2.history['auc'],\n",
    "    'val_auc': history_phase1.history['val_auc'] + history_phase2.history['val_auc']\n",
    "}\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['loss'], label='Train Loss')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0].set_title('Model Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# AUC plot\n",
    "axes[1].plot(history['auc'], label='Train AUC')\n",
    "axes[1].plot(history['val_auc'], label='Val AUC')\n",
    "axes[1].set_title('Model AUC')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('AUC')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights('best_model.h5')\n",
    "\n",
    "# Predictions on validation set\n",
    "val_predictions = model.predict(val_generator, verbose=1)\n",
    "val_predictions_binary = (val_predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "val_auc = roc_auc_score(val_data['target'].values, val_predictions)\n",
    "print(f\"\\nValidation AUC: {val_auc:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(val_data['target'].values, val_predictions_binary)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_data['target'].values, val_predictions_binary, \n",
    "                          target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='image_path',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "test_predictions = model.predict(test_generator, verbose=1)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'image_name': test_df['image_name'],\n",
    "    'target': test_predictions.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission file created: submission.csv\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save('melanoma_classifier_final.h5')\n",
    "print(\"Model saved as melanoma_classifier_final.h5\")\n",
    "\n",
    "# Save model in TensorFlow SavedModel format (recommended)\n",
    "model.save('melanoma_classifier_saved_model')\n",
    "print(\"Model saved as melanoma_classifier_saved_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis - Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "sample_indices = np.random.choice(len(val_data), 8, replace=False)\n",
    "sample_data = val_data.iloc[sample_indices]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (ax, (_, row)) in enumerate(zip(axes, sample_data.iterrows())):\n",
    "    img = Image.open(row['image_path'])\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Get prediction\n",
    "    img_array = cv2.imread(row['image_path'])\n",
    "    img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    pred = model.predict(img_array, verbose=0)[0][0]\n",
    "    \n",
    "    true_label = 'Malignant' if row['target'] == 1 else 'Benign'\n",
    "    pred_label = 'Malignant' if pred > 0.5 else 'Benign'\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    \n",
    "    ax.set_title(f\"True: {true_label}\\nPred: {pred_label} ({pred:.2f})\", color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
